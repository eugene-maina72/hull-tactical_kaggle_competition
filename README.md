# ğŸ§  Predicting Market Excess Returns with Machine Learning

## Overview
This project applies **machine learning** methods to predict **market forward excess returns**, aiming to design a **volatility-controlled investment strategy** that can potentially outperform the S&P 500.

The project follows the **CRISP-DM** methodology â€” from **data understanding** to **deployment-ready evaluation** â€” and compares two main modeling approaches:  
a **Neural Network (PyTorch)** and **XGBoost (tree-based gradient boosting)**.

---

## ğŸ¯ Objectives
- Predict **market excess returns** using structured financial data.  
- Design a **systematic strategy** that:
  - Maximizes excess return over the benchmark.  
  - Keeps volatility â‰¤ **120% of the market** (vol-cap).  
- Evaluate and compare the performance of different model architectures.

---

## ğŸ“Š Data Summary
The dataset contains daily financial indicators grouped by domain:

| Prefix | Category | Description |
|:-------|:----------|:-------------|
| `M*` | Market Dynamics | Technical / market features |
| `E*` | Economic | Macro indicators |
| `V*` | Volatility | Volatility measures |
| `I*` | Interest Rates | Yield curve and rates |
| `P*` | Pricing | Price and valuation ratios |
| `S*` | Sentiment | Investor sentiment features |
| `D*` | Dummy | Binary / categorical encodings |

**Target variable:** `market_forward_excess_returns` â€” the forward return in excess of the S&P 500 benchmark.  
**Benchmark variable:** `forward_returns` â€” proxy for the market (S&P 500).

---

## ğŸ§¹ Data Preparation
- Imputed missing values **by feature group**:
  - `M*`, `P*` â†’ median  
  - `V*`, `E*` â†’ mean  
  - `I*` â†’ forward/backward fill  
  - `S*` â†’ set to neutral (0)  
  - `D*` â†’ mode or 0  
- Added `_isna` binary flags for missingness (informative feature).  
- Scaled continuous variables using **StandardScaler**.  
- Split chronologically (80/20) to avoid lookahead bias.  
- Excluded all forward-looking columns except the benchmark `forward_returns`.

---

## ğŸ¤– Models

### 1ï¸âƒ£ Neural Network (PyTorch)
**Architecture:**  
Two hidden layers (128 â†’ 64 â†’ 1), ReLU activation, Dropout (0.2 / 0.1), L2 regularization.  
**Loss:** Huber (robust to outliers).  
**Training:** Early stopping by **validation IC (Spearman)**.

**Performance:**

| Metric | Value |
|:--------|:------|
| RMSE | 0.0111 |
| MAE | 0.0079 |
| RÂ² | 0.0025 |
| IC (Spearman) | 0.0526 |
| Hit Rate | 52.9% |
| Ann. Return | 2.43% |
| Ann. Vol | 15.6% |
| Sharpe (Vol-Capped @120%) | 0.16 |

**Observations:**
- The network detected a weak but statistically valid signal (IC â‰ˆ 0.05).
- Regression accuracy near noise level (expected for daily excess returns).
- Volatility-capped returns show modest but positive performance.

---

### 2ï¸âƒ£ XGBoost (Tree Ensemble)
**Parameters:**  
`n_estimators=800`, `max_depth=4`, `learning_rate=0.03`,  
`subsample=0.7`, `colsample_bytree=0.7`, `reg_lambda=5`.

**Evaluation:** Spearman IC.  
**Position sizing:** Z-scored predictions (clipped Â±3), vol-capped at 120%.

**Performance (Pre-Tuning):**

| Metric | Value |
|:--------|:------|
| Ann. Return | 3.21% |
| Ann. Vol | 14.3% |
| Sharpe (Vol-Capped) | 0.22 |

**Observations:**
- Outperformed the neural network in IC and Sharpe ratio.
- Smoother cumulative return curve and better out-of-sample stability.
- Confirms **tree-based models** are well-suited for structured, noisy market data.

---

## ğŸ“ˆ Strategy Construction
- Trading signals converted into positions:  
  `position = zscore(prediction)` (clipped Â±3).  
- Volatility targeting enforced via 20-day rolling std (shifted 1 day to avoid lookahead).  
- Strategy returns calculated as:
- Turnover cost applied (default 5 bps per unit change in position).

---

## âš™ï¸ Next Steps
- ğŸ”§ Tune XGBoost hyperparameters (depth, learning rate, Î»).  
- ğŸ“… Test multi-day forward horizons (5- and 10-day labels).  
- ğŸ’¸ Include transaction costs and report **net Sharpe**.  
- ğŸ§© Ensemble models (NN + XGB) for stability.  
- ğŸ§­ Implement walk-forward validation for live-like testing.

---

## ğŸ§¾ Key Insights
- Predictability of daily excess returns exists (IC ~0.05â€“0.07) but is **small and noisy**.  
- Proper **risk management** (vol targeting, cost control) converts small signals into tradable edges.  
- **Tree models** outperform deep nets for tabular financial data.  
- Framework is modular â€” extendable to cross-asset, multi-horizon, or regime detection models.

---

## ğŸ§© Tech Stack
- **Language:** Python 3.12  
- **Libraries:** pandas, numpy, scikit-learn, torch, xgboost, matplotlib, seaborn  
- **Framework:** CRISP-DM  
- **Outputs:** Reproducible notebook (`hull-notebook.ipynb`) and visual analytics

---

## ğŸ“¦ Repository Structure

```markdown
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚â”€â”€ hull-notebook.ipynb 
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ neural_net.py
â”‚ â””â”€â”€ xgb_model.py
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ correlation_top_20.png
â”‚ â”œâ”€â”€ cumulative_return_nn.png
â”‚ â””â”€â”€ cumulative_return_xgb.png
â””â”€â”€ README.md
```
## ğŸ“š References
- LÃ³pez de Prado, M. *Advances in Financial Machine Learning*  
- Bailey et al., *Pseudo-Mathematics and Financial Charlatanism*  
- Jensenâ€™s Alpha and Information Coefficient theory  

---

## Contact & Ownership


Eugene Maina |
Data Scientist | RPA Developer

* [LinkedIn](https://www.linkedin.com/in/eugene-maina-4a8b9a128/) | [GitHub](https://github.com/eugene-maina72) | [Email](mailto:eugenemaina72@gmail.com)

